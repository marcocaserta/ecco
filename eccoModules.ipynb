{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eccoModules.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/marcocaserta/ecco/blob/master/eccoModules.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "3RAN1sKJevgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We'll start by creating a directory in which we'll define our new\n",
        "# module to be imported.\n",
        "!mkdir -p local_modules/ecco_modules"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IwdvQzvPez0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd local_modules"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qr9bJ_Y0e-vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27550a38-e311-4da7-b848-8be0e8ffbea8"
      },
      "cell_type": "code",
      "source": [
        "!ls local_modules/ecco_modules/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ecco.py  __init__.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DpRfnY4X2bFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb268a2e-fa3e-4cd6-ba0e-6dabdf06691a"
      },
      "cell_type": "code",
      "source": [
        "%%writefile local_modules/ecco_modules/ecco.py\n",
        "# Save a module init file that contains a custom function that we'll use\n",
        "# to verify that import works.\n",
        "\n",
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io, os\n",
        "import re, string\n",
        "import textwrap\n",
        "import html\n",
        "#from IPython.display import display, HTML\n",
        "\n",
        "def createDataFrame(df, dfQuery):\n",
        "  count             = []\n",
        "  percent           = []\n",
        "  dfQuery.tokenized = tknz(dfQuery.tokenized)\n",
        "  lenQuery        = len(dfQuery.tokenized)\n",
        "  for i in range(len(df)):\n",
        "      vect     = tknz(df.iloc[i].tokenized)\n",
        "      nSent    = len(vect)\n",
        "      nShared  = sum([w in vect for w in dfQuery.tokenized])\n",
        "      count.append(nShared)\n",
        "      percent.append(nShared/lenQuery)\n",
        "  df[\"nShared\"] = count\n",
        "  df[\"percent\"] = percent\n",
        "\n",
        "  return df, dfQuery, lenQuery\n",
        "\n",
        "# preprocess tokenized senteces\n",
        "def tknz(sentence):\n",
        "  sentence = sentence.strip(\"[,']\")\n",
        "  regex = re.compile(' [%s]' % re.escape(string.punctuation))\n",
        "  sentence = regex.sub('', sentence)\n",
        "  vect = sentence.strip(\",\").split(\"'\")\n",
        "  final = [w.strip(\",\") for w in vect]\n",
        "  return final\n",
        "\n",
        "def setTitle(dfQuery):\n",
        "    titleText = \"<center><h4>Query : <b>\" + dfQuery.sentence.strip(\"[] '\") + \"</b> </h4>\"\n",
        "    titleText += \"<i>\" + str(dfQuery.tokenized) + \"</i></center>\"\n",
        "    return titleText\n",
        "\n",
        "def setTitle2(dfQuery):\n",
        "  \n",
        "    titleText = \"Query : \" + color.BOLD + dfQuery.sentence.strip(\"[] '\") + color.END + \"\\n\"\n",
        "    titleText += color.ITALIC + str(dfQuery.tokenized) + color.END\n",
        "    return titleText\n",
        "  \n",
        "def formatting(sent,i):\n",
        "    block= \"<li>\" + sent.previous.strip(\"[] '\") + \" \" \n",
        "    block+= \"<b>\" + sent.sentence.strip(\"[] '\") + \"</b>\" + \" \"\n",
        "    block+= sent.next.strip(\"[] '\") + \"</li>\"\n",
        "    block+= \"<font color='#999999' size='1'>(\" + str(i+1) + \"-Sentence id = \" + str(sent.id)\n",
        "    block+= \"; score = \" + str(np.round(sent.score,3))\n",
        "    block+= \"; overlap = \" + str(np.round(sent.percent,2))\n",
        "    block+= \"; keywords = \" + sent.tokenized + \") </font>\"\n",
        "    return block\n",
        "\n",
        "def formatting2(sent,i):\n",
        "  block = color.BULLET + \" \" + html.unescape(sent.previous.strip(\"[] '\")) + \" \" \n",
        "  block+= color.BOLD + \" \" + html.unescape(sent.sentence.strip(\"[] '\")) + color.END + \" \"\n",
        "  block+= html.unescape(sent.next.strip(\"[] '\")) + \"\\n\"\n",
        "  block+= color.DIM + \"\\n(\" + str(i+1) + \"-Sentence id = \" + str(sent.id)\n",
        "  block+= \"; score = \" + str(np.round(sent.score,3))\n",
        "  block+= \"; overlap = \" + str(np.round(sent.percent,2))\n",
        "  block+= \"; keywords = \" + sent.tokenized + \")\" + color.END\n",
        "  return block\n",
        "\n",
        "def createBlocks(ddf):\n",
        "  if len(ddf) == 0:\n",
        "    return []\n",
        "  ww = []\n",
        "  for i in range(len(ddf)):\n",
        "      block = formatting(ddf.iloc[i],i)\n",
        "      ww.append(block)  \n",
        "  return ww\n",
        "\n",
        "\n",
        "def createTable(df, nQuery):\n",
        "    bins = [i for i in range(nQuery+1)]\n",
        "    ncounting = []\n",
        "    for pp in bins:\n",
        "        ncounting.append(df.loc[df.nShared==pp, 'nShared' ].count())\n",
        "    table = pd.DataFrame({\n",
        "        \"nr. words\" : bins,\n",
        "        \"percent\" : [np.round(i/nQuery,3) for i in bins],\n",
        "        \"freq\"    : ncounting\n",
        "    })\n",
        "    table = table.reindex(['nr. words', 'percent','freq'], axis=1)\n",
        "    return table\n",
        "  \n",
        "def createTableYear(df,periods):\n",
        "    ncounting = []\n",
        "    bins = periods\n",
        "    for yy in bins:\n",
        "      ncounting.append(df.loc[df.year==yy, 'year'].count())\n",
        "    tableYear = pd.DataFrame({\"year\": bins, \"freq\":ncounting})\n",
        "    tableYear = tableYear.reindex(['year','freq'], axis=1)\n",
        "    return tableYear\n",
        "  \n",
        "def createTableWords(df, nTop):\n",
        "    nWords = 10\n",
        "    vecs = []\n",
        "    for i in range(len(df)):\n",
        "      vect = tknz(df.iloc[i].tokenized)\n",
        "      vecs.append(vect)\n",
        "    dd = {key:0 for i in range(nTop) for key in vecs[i] }\n",
        "    for i in range(nTop):\n",
        "        for w in vecs[i]:\n",
        "            dd[w] += 1\n",
        "\n",
        "    words = sorted(dd, key=dd.get, reverse=True)[:nWords]\n",
        "    vals  = [dd[w] for w in words]\n",
        "    percent = [np.round(v/nTop, 3) for v in vals]\n",
        "    dfWords= pd.DataFrame({\"word\":words,\"freq\":vals, \"percent\": percent})\n",
        "    dfWords = dfWords.reindex(['word', 'percent','freq'], axis=1)\n",
        "    return dfWords\n",
        "  \n",
        "def createChart1(df, lenQuery):\n",
        "    plt.figure(figsize=(4,4)) \n",
        "    bins = [i for i in range(lenQuery+1)]\n",
        "    ax = plt.gca()\n",
        "    ax.hist(df.nShared, bins=bins, edgecolor=\"white\", linewidth=1.5, alpha=0.9, align=\"left\")\n",
        "    ax.set_xticks(bins)\n",
        "    ax.set_title(\"Distribution of Sentences over Overlap Values\")\n",
        "    plt.show()\n",
        "\n",
        "def createChart2(df, lenQuery):\n",
        "    plt.figure(figsize=(4,4)) \n",
        "    ax = plt.gca()\n",
        "    bins = np.arange(np.min(df.year), np.max(df.year)+2)\n",
        "    ax.hist(df.year, bins=bins, align=\"left\", edgecolor=\"white\", linewidth=1.5, alpha=0.9)\n",
        "    ax.set_xticks(bins[:-1])\n",
        "    ax.set_title(\"Distribution of Top Sentences over Time Period\")\n",
        "\n",
        "    \n",
        "def createChart3(dfWords, lenQuery):\n",
        "    plt.figure(figsize=(4,4)) \n",
        "    ax = plt.gca()\n",
        "    ax.bar(dfWords.word,dfWords.freq, edgecolor=\"white\", linewidth=1.5, alpha=0.9)\n",
        "    for tick in ax.get_xticklabels():\n",
        "      tick.set_rotation(60)\n",
        "    ax.set_title(\"Distribution of Words among Top Sentences\")\n",
        "    plt.show()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting local_modules/ecco_modules/ecco.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}